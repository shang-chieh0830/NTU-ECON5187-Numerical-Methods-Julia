{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e74d633",
   "metadata": {},
   "source": [
    "# Homework on MSLE\n",
    "\n",
    "Recall that in the previous homework we have Model A and its log-likelihood function of observation $i$ is as follows.\n",
    "\n",
    "\\begin{align}\n",
    " y_i & = \\alpha + x_i' \\beta + v_i - u_i,\\\\\n",
    " v_i & \\sim N(0, \\sigma_v^2), \\\\\n",
    " u_i & \\sim N^+(0, \\sigma_u^2),\n",
    "\\end{align}\n",
    " \n",
    "\\begin{aligned}\n",
    "L_i = - \\ln \\left(\\frac{1}{2}\\right) -\\frac{1}{2}\\ln (\\sigma_v^2 + \\sigma_u^2) + \\ln\n",
    "\\phi\\left(\\frac{\\epsilon_i}{\\sqrt{\\sigma_v^2 + \\sigma_u^2}} \\right) +\n",
    "\\ln \\Phi\\left(\\frac{\\mu_{*i}}{\\sigma_*} \\right),\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "where $\\phi(z)$ and $\\Phi(z)$ are the PDF and CDF of a standard normal distribution. Also,\n",
    "\n",
    "\\begin{aligned}\n",
    " \\mu_{*i}  = \\frac{-\\sigma_u^2 \\epsilon_i}{\\sigma_v^2 + \\sigma_u^2},\\qquad\n",
    " \\sigma_*^2  = \\frac{\\sigma_v^2  \\sigma_u^2}{\\sigma_v^2 + \\sigma_u^2}. \n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "###### 1. Write a Julia function of the Model's log-likelihood function.\n",
    "Write a function for Model A's log-likelihood that is suitable for estimating using the Monte Carlo simulation approach (MCSA of Section 1.4 in the lecture note). \n",
    "\n",
    "  - Name the function `NHN_msle`.\n",
    "  - Use the Monte Carlo method (not the Quasi Monte Carlo method) to draw samples of $u_i^s$, $s=1,\\ldots,S$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08caa46d",
   "metadata": {},
   "source": [
    "###### 2. Empirical Estimation\n",
    "The attached dataset, `sampledata.csv`, contains data of agricultural production from India. The variables are the follows. They have been converged to appropriate units (using log, etc.) so no further data processing is necessary.\n",
    "\n",
    "\n",
    "|          |  |        |\n",
    "|-------------------------------------|---|---------------------|\n",
    "| yvar: rice output                   |   | Lland: land         |\n",
    "| Plland: irrigated land              |   | Llabor: labor       |\n",
    "| Lbull: bull cost                    |   | Lcost: other costs  |\n",
    "| yr: production year                 |   | age: age of farmers |\n",
    "| school: farmers' years of schooling |   | yr_1: same as year  |\n",
    "\n",
    "\n",
    "Your work is to use `NHN_msle` to estimate the data with the following specification.\n",
    "\n",
    "$yvar_i = \\alpha + \\beta_1 Lland_i + \\beta_2 Plland_i + \\beta_3 Llabor_i + \\beta_4 Lbull_i + \\beta_5 Lcost_i + \\beta_6 yr_i + v_i - u_i$.\n",
    "  \n",
    "You may use the following code to read in the data.\n",
    "\n",
    "```julia\n",
    "####################\n",
    "using DataFrames, CSV\n",
    "df = DataFrame(CSV.File(\"sampledata.csv\"))\n",
    "y = df[:, \"yvar\"]       # the dep var\n",
    "x = Matrix(df[:, 2:7])  # the indep vars, not including a constant\n",
    "####################\n",
    "```\n",
    "\n",
    "***The required result is a table with three columns: the 1st column is the coefficients, the 2nd column is the standard errors, and the 3rd column is the $t$ statistics.***\n",
    "\n",
    "  - The table is preferably in Dataframe. How to convert a matrix to a DataFrame? Ask ChatGPT!\n",
    "\n",
    "\n",
    "###### 2.1: The Estimation Guidelines\n",
    "  \n",
    "  - You may use $-0.1$ as the initial values for all parameters. Or you may use the OLS result as the initial values for the $\\alpha$ and $\\beta$ coefficients (`x2=hcat(ones(size(y,1), 1), x); ols=inv(x2'x2)*(x2'y)`). Or, you may choose any initial values that seem to be reasonable choices. However, you _**cannot**_ use the true answer (provided below) as the initial values.\n",
    "\n",
    "  - Set the value of $S$ (the number of random draws on $u$) to be $S=2^{10} -1$.\n",
    "\n",
    "  - I strongly suggest that your program uses the `autodiff = :forward` option (which uses automatic differentiation) in the estimation.\n",
    "  \n",
    "    - The `autodiff = :forward` option puts stringent requirements on data types which may not easy to work out. I suggest that you start with your program without the option (which would then default to numerical finite differences that is easier on the data). After you have a working program, you may add the option back and see if it works. Most likely you'll have error messages and you have to work out the issues. If you can't make it work, that's fine. Try your best.  \n",
    "  \n",
    "\n",
    "- Hint 1: Look at $|g(x)|$ to judge whether it is converged. It should be smaller than the convergence criterion. \n",
    "  \n",
    "- Hint 2: The answer from the MSLE should be close to but not exactly the same as that from the MLE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "025dcee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271×6 Matrix{Float64}:\n",
       " -0.210721  0.0       5.26269  4.41884  0.0       6.0\n",
       " -0.210721  0.0       4.84419  4.20469  0.0       7.0\n",
       " -0.210721  0.0       4.39445  3.78419  0.0       8.0\n",
       " -0.210721  0.0       4.79579  4.23411  4.51501   9.0\n",
       " -0.211476  0.0       5.54908  4.95583  4.31431  10.0\n",
       "  0.482426  0.0       5.53733  5.06259  0.0       6.0\n",
       "  0.19062   0.0       5.17048  4.58497  0.0       7.0\n",
       "  0.482426  0.0       5.57595  4.86754  0.0       9.0\n",
       "  0.481671  0.0       5.38907  4.96981  0.0      10.0\n",
       " -0.210721  0.0       4.31749  3.68888  0.0       7.0\n",
       " -0.916291  0.0       4.07754  3.43399  0.0       8.0\n",
       " -0.210721  0.0       5.96101  4.02535  3.76898   6.0\n",
       " -0.210721  0.0       5.47646  4.64439  3.8907    7.0\n",
       "  ⋮                                               ⋮\n",
       "  1.58858   0.669422  8.49208  6.82546  7.15436  10.0\n",
       "  2.06051   0.168153  8.52258  7.06133  7.66435   1.0\n",
       "  2.09924   0.11152   8.70814  7.32251  7.11658   2.0\n",
       "  1.63705   0.315175  8.16877  6.63857  6.88085   3.0\n",
       "  1.69928   0.296161  8.28954  6.52356  7.26189   4.0\n",
       "  1.21788   0.538462  8.22094  6.51323  6.56129   5.0\n",
       " -1.20397   0.0       4.52179  4.02535  0.0       6.0\n",
       "  0.262364  0.0       5.86079  5.23111  3.65181   7.0\n",
       "  0.802002  0.452915  7.48941  5.8693   6.10984   2.0\n",
       "  0.802002  0.363229  7.23993  5.91889  5.79586   3.0\n",
       "  0.887891  0.497942  7.52726  5.33754  6.52888   4.0\n",
       "  0.19062   0.0       5.68017  4.52179  0.0       5.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, CSV\n",
    "df = DataFrame(CSV.File(\"sampledata.csv\"))\n",
    "y = df[:, \"yvar\"]       # the dep var\n",
    "x = Matrix(df[:, 2:7])  # the indep vars, not including a constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1863473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res =  * Status: success\n",
      "\n",
      " * Candidate solution\n",
      "    Final objective value:     9.211587e+01\n",
      "\n",
      " * Found with\n",
      "    Algorithm:     Newton's Method\n",
      "\n",
      " * Convergence measures\n",
      "    |x - x'|               = 9.23e-09 ≰ 0.0e+00\n",
      "    |x - x'|/|x'|          = 2.71e-09 ≰ 0.0e+00\n",
      "    |f(x) - f(x')|         = 1.99e-13 ≰ 0.0e+00\n",
      "    |f(x) - f(x')|/|f(x')| = 2.16e-15 ≰ 0.0e+00\n",
      "    |g(x)|                 = 2.35e-08 ≤ 1.0e-07\n",
      "\n",
      " * Work counters\n",
      "    Seconds run:   6  (vs limit Inf)\n",
      "    Iterations:    9\n",
      "    f(x) calls:    25\n",
      "    ∇f(x) calls:   25\n",
      "    ∇²f(x) calls:  9\n",
      "\n",
      "Optim.minimizer(res) = [1.572047299380956, 0.284785604988363, 0.23794041558422452, 1.1540155975595687, -0.4169973004689726, 0.00545148812134091, 0.03399107182667159, -3.40983942221118, -1.3991363475467133]\n",
      "exp((Optim.minimizer(res))[end - 1]) = 0.03304650648479347\n",
      "exp((Optim.minimizer(res))[end]) = 0.24681003000875973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24681003000875973"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions, Optim, LinearAlgebra, ForwardDiff, Random\n",
    "\n",
    "\n",
    "function NHN_msle(y, x, α, β, log_σ²_v, log_σ²_u)\n",
    "    σ²_v = exp(log_σ²_v)\n",
    "    σ²_u = exp(log_σ²_u)\n",
    "    σ_v  = exp(0.5*log_σ²_v)\n",
    "    σ_u  = exp(0.5*log_σ²_u)\n",
    "    ϵ  = y .- α .- x*β\n",
    "\n",
    "    f(e, sigma_v) = pdf(Normal(0, sigma_v), e) \n",
    "    S=2^11 -1\n",
    "    \n",
    "    rng = Xoshiro(123)\n",
    "    disTN = TruncatedNormal(0.0, σ_u, 0.0, Inf)    # half-normal dist  \n",
    "    u_list = rand(rng, disTN, S)\n",
    "\n",
    "    logLike = Array{Real}(undef, size(y,1))\n",
    "    for i in 1:size(y,1) \n",
    "       logLike[i] = log(sum(f.(ϵ[i,1] .+ u_list, σ_v))/S)\n",
    "    end\n",
    "    \n",
    "    return  logLike = -sum(logLike)  # better than running sum\n",
    "    \n",
    "end\n",
    "\n",
    "nofxvar=6\n",
    "func = TwiceDifferentiable(vars -> NHN_msle(y, x, vars[1], vars[2:nofxvar+1], vars[end-1], vars[end]),\n",
    "                           ones(nofxvar+3))\n",
    "\n",
    "x2=hcat(ones(size(y,1), 1), x); ols=inv(x2'x2)*(x2'y)\n",
    "#myinit = vcat(ols, -0.1, -0.1) # or -0.1*ones(nofxvar+3)\n",
    "myinit = [1.59, 0.29, 0.23, 1.15,-0.42, 0.007, 0.034, log(0.256), log(0.033)]\n",
    "\n",
    "res= optimize(func, myinit, Newton(),\n",
    "                Optim.Options(g_tol = 1e-7,\n",
    "                              iterations = 2000) )\n",
    "\n",
    "@show res\n",
    "@show Optim.minimizer(res)\n",
    "@show exp(Optim.minimizer(res)[end-1])\n",
    "@show exp(Optim.minimizer(res)[end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "817ab496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimation table is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9×3 Matrix{Float64}:\n",
       "  1.57205     0.345642     4.5482\n",
       "  0.284786    0.0689715    4.12903\n",
       "  0.23794     0.172136     1.38228\n",
       "  1.15402     0.0793789   14.5381\n",
       " -0.416997    0.0582806   -7.155\n",
       "  0.00545149  0.013043     0.417963\n",
       "  0.0339911   0.00786219   4.32336\n",
       "  0.0330465   0.00905215   3.65068\n",
       "  0.24681     0.0418909    5.89173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>9×3 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">res_coeff</th><th style = \"text-align: left;\">stderror</th><th style = \"text-align: left;\">t_stats</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">1.57205</td><td style = \"text-align: right;\">0.345642</td><td style = \"text-align: right;\">4.5482</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">0.284786</td><td style = \"text-align: right;\">0.0689715</td><td style = \"text-align: right;\">4.12903</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">0.23794</td><td style = \"text-align: right;\">0.172136</td><td style = \"text-align: right;\">1.38228</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">1.15402</td><td style = \"text-align: right;\">0.0793789</td><td style = \"text-align: right;\">14.5381</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">-0.416997</td><td style = \"text-align: right;\">0.0582806</td><td style = \"text-align: right;\">-7.155</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">0.00545149</td><td style = \"text-align: right;\">0.013043</td><td style = \"text-align: right;\">0.417963</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">0.0339911</td><td style = \"text-align: right;\">0.00786219</td><td style = \"text-align: right;\">4.32336</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">0.0330465</td><td style = \"text-align: right;\">0.00905215</td><td style = \"text-align: right;\">3.65068</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">0.24681</td><td style = \"text-align: right;\">0.0418909</td><td style = \"text-align: right;\">5.89173</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& res\\_coeff & stderror & t\\_stats\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1.57205 & 0.345642 & 4.5482 \\\\\n",
       "\t2 & 0.284786 & 0.0689715 & 4.12903 \\\\\n",
       "\t3 & 0.23794 & 0.172136 & 1.38228 \\\\\n",
       "\t4 & 1.15402 & 0.0793789 & 14.5381 \\\\\n",
       "\t5 & -0.416997 & 0.0582806 & -7.155 \\\\\n",
       "\t6 & 0.00545149 & 0.013043 & 0.417963 \\\\\n",
       "\t7 & 0.0339911 & 0.00786219 & 4.32336 \\\\\n",
       "\t8 & 0.0330465 & 0.00905215 & 3.65068 \\\\\n",
       "\t9 & 0.24681 & 0.0418909 & 5.89173 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m9×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m res_coeff   \u001b[0m\u001b[1m stderror   \u001b[0m\u001b[1m t_stats   \u001b[0m\n",
       "     │\u001b[90m Float64     \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64   \u001b[0m\n",
       "─────┼────────────────────────────────────\n",
       "   1 │  1.57205     0.345642     4.5482\n",
       "   2 │  0.284786    0.0689715    4.12903\n",
       "   3 │  0.23794     0.172136     1.38228\n",
       "   4 │  1.15402     0.0793789   14.5381\n",
       "   5 │ -0.416997    0.0582806   -7.155\n",
       "   6 │  0.00545149  0.013043     0.417963\n",
       "   7 │  0.0339911   0.00786219   4.32336\n",
       "   8 │  0.0330465   0.00905215   3.65068\n",
       "   9 │  0.24681     0.0418909    5.89173"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefficient vector\n",
    "_coevec = Optim.minimizer(res)\n",
    "res_coeff = deepcopy(_coevec)      # keep _coevec untouched\n",
    "res_coeff[end-1] = exp(_coevec[end-1])       # convert the unit \n",
    "res_coeff[end] = exp(_coevec[end])           # convert the unit \n",
    "\n",
    " \n",
    "# use Hessian matrix to obtain std. err.\n",
    "\n",
    "res_Hessian  = Optim.hessian!(func, _coevec)  # Hessain evaluated at the coeff vector, this is why we used deepcopy(), func is still in log unit, so we need to use _coevec (in log unit as well)\n",
    "var_cov_matrix = inv(res_Hessian)             # don't need the \"negative\" of Hessian. Why? Since already take negative in NHN_mle\n",
    "stderror  = sqrt.(diag(var_cov_matrix))\n",
    "stderror[end-1] = res_coeff[end-1]*stderror[end-1]  # convert the unit using the delta method, exp(hat rho)*sigma_rho\n",
    "stderror[end] = res_coeff[end]*stderror[end]\n",
    "t_stats = res_coeff ./ stderror\n",
    "res_table = hcat(res_coeff, stderror, t_stats)\n",
    "\n",
    "println(\"The estimation table is\")\n",
    "res_table |> display\n",
    "\n",
    "\n",
    "using DataFrames\n",
    "\n",
    "DataFrame(res_table,[:res_coeff, :stderror, :t_stats])"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
