{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c09b56",
   "metadata": {},
   "source": [
    "# Homework on MLE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff1e081",
   "metadata": {},
   "source": [
    "#####   Estimate a Normal-Half Normal Model.\n",
    "\n",
    "Consider the Model A below:\n",
    "\n",
    "\\begin{aligned}\n",
    " y_i & = \\alpha + x_i' \\beta + v_i - u_i,\\\\\n",
    " v_i & \\sim N(0, \\sigma_v^2), \\\\\n",
    " u_i & \\sim N^+(0, \\sigma_u^2).\n",
    "\\end{aligned}\n",
    " \n",
    " \n",
    "The following is Model A's log-likelihood function of the $i$th observation. \n",
    "\n",
    "\\begin{align}\n",
    "L_i = - \\ln \\left(\\frac{1}{2}\\right) -\\frac{1}{2}\\ln (\\sigma_v^2 + \\sigma_u^2) + \\ln\n",
    "\\phi\\left(\\frac{\\epsilon_i}{\\sqrt{\\sigma_v^2 + \\sigma_u^2}} \\right) +\n",
    "\\ln \\Phi\\left(\\frac{\\mu_{*i}}{\\sigma_*} \\right),\n",
    "\\end{align}\n",
    "\n",
    "where $\\phi(z)$ and $\\Phi(z)$ are the PDF and CDF of a standard normal distribution. Also,\n",
    "\n",
    "\\begin{aligned}\n",
    " \\mu_{*i}  = \\frac{-\\sigma_u^2 \\epsilon_i}{\\sigma_v^2 + \\sigma_u^2},\\qquad\n",
    " \\sigma_*^2  = \\frac{\\sigma_v^2  \\sigma_u^2}{\\sigma_v^2 + \\sigma_u^2}. \n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "The attached dataset, `sampledata.csv`, contains data of agricultural production from India. The variables are the follows. They have been converted to appropriate units (taking log, etc.) so no further data processing is necessary.\n",
    "\n",
    "\n",
    "|          |  |        |\n",
    "|-------------------------------------|---|---------------------|\n",
    "| yvar: rice output                   |   | Lland: land         |\n",
    "| Plland: irrigated land              |   | Llabor: labor       |\n",
    "| Lbull: bull cost                    |   | Lcost: other costs  |\n",
    "| yr: production year                 |   | age: age of farmers |\n",
    "| school: farmers' years of schooling |   | yr_1: same as year  |\n",
    "\n",
    "\n",
    "The Indian farming model is the follows.\n",
    "\n",
    "$yvar_i = \\alpha + \\beta_1 Lland_i + \\beta_2 Plland_i + \\beta_3 Llabor_i + \\beta_4 Lbull_i + \\beta_5 Lcost_i + \\beta_6 yr_i + v_i - u_i$.\n",
    "  \n",
    "You may use the following code to read in the data.\n",
    "\n",
    "```julia\n",
    "####################\n",
    "using DataFrames, CSV\n",
    "df = DataFrame(CSV.File(\"sampledata.csv\"))\n",
    "y = df[:, \"yvar\"]       # the dep var\n",
    "x = Matrix(df[:, 2:7])  # the indep vars, not including a constant\n",
    "####################\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6bebbe",
   "metadata": {},
   "source": [
    "###### Your work: \n",
    "\n",
    "- Based on (1), write a program of Model A's log-likelihood function and call it `NHN_mle`. You may use `loglike5` in the lecture note as the reference. \n",
    "\n",
    "\n",
    "- Use `NHN_mle` to estimate the Indian farming model. You may conduct the estimation using `Optim` or your own programs. The required result is a table with three columns: the 1st column is the coefficients, the 2nd column is the standard errors, and the 3rd column is the $t$ statistics. They do not have to be in DataFrames.\n",
    "\n",
    "\n",
    "- The Estimation Guidelines:\n",
    "  \n",
    "  - You may use $-0.1$ as the initial values for all parameters. Or you may use the OLS result as the initial values for the $\\alpha$ and $\\beta$ coefficients (`x2=hcat(ones(size(y,1), 1), x); ols=inv(x2'x2)*(x2'y)`). Or, you may choose any initial values that seem to be reasonable choices. However, you _**cannot**_ use the true answer as the initial values.\n",
    "\n",
    "  - I strongly suggest that your program uses the `autodiff = :forward` option (which uses automatic differentiation) in the estimation.\n",
    "  \n",
    "    - The `autodiff = :forward` option puts stringent requirements on data types which may not easy to work out. I suggest that you start with your program without the option (which would then default to numerical finite differences that is easier on the data). After you have a working program, you may add the option back and see if it works. Most likely you'll have error messages and you have to work out the issues. If you can't make it work, that's fine. Try your best.  \n",
    "  \n",
    "- Hint: Look at $|g(x)|$ to judge whether it is converged. It should be smaller than the convergence criterion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b70d7648",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271×6 Matrix{Float64}:\n",
       " -0.210721  0.0       5.26269  4.41884  0.0       6.0\n",
       " -0.210721  0.0       4.84419  4.20469  0.0       7.0\n",
       " -0.210721  0.0       4.39445  3.78419  0.0       8.0\n",
       " -0.210721  0.0       4.79579  4.23411  4.51501   9.0\n",
       " -0.211476  0.0       5.54908  4.95583  4.31431  10.0\n",
       "  0.482426  0.0       5.53733  5.06259  0.0       6.0\n",
       "  0.19062   0.0       5.17048  4.58497  0.0       7.0\n",
       "  0.482426  0.0       5.57595  4.86754  0.0       9.0\n",
       "  0.481671  0.0       5.38907  4.96981  0.0      10.0\n",
       " -0.210721  0.0       4.31749  3.68888  0.0       7.0\n",
       " -0.916291  0.0       4.07754  3.43399  0.0       8.0\n",
       " -0.210721  0.0       5.96101  4.02535  3.76898   6.0\n",
       " -0.210721  0.0       5.47646  4.64439  3.8907    7.0\n",
       "  ⋮                                               ⋮\n",
       "  1.58858   0.669422  8.49208  6.82546  7.15436  10.0\n",
       "  2.06051   0.168153  8.52258  7.06133  7.66435   1.0\n",
       "  2.09924   0.11152   8.70814  7.32251  7.11658   2.0\n",
       "  1.63705   0.315175  8.16877  6.63857  6.88085   3.0\n",
       "  1.69928   0.296161  8.28954  6.52356  7.26189   4.0\n",
       "  1.21788   0.538462  8.22094  6.51323  6.56129   5.0\n",
       " -1.20397   0.0       4.52179  4.02535  0.0       6.0\n",
       "  0.262364  0.0       5.86079  5.23111  3.65181   7.0\n",
       "  0.802002  0.452915  7.48941  5.8693   6.10984   2.0\n",
       "  0.802002  0.363229  7.23993  5.91889  5.79586   3.0\n",
       "  0.887891  0.497942  7.52726  5.33754  6.52888   4.0\n",
       "  0.19062   0.0       5.68017  4.52179  0.0       5.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, CSV\n",
    "df = DataFrame(CSV.File(\"sampledata.csv\"))\n",
    "y = df[:, \"yvar\"]       # the dep var\n",
    "x = Matrix(df[:, 2:7])  # the indep vars, not including a constant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d29d37c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res =  * Status: success\n",
      "\n",
      " * Candidate solution\n",
      "    Final objective value:     9.336604e+01\n",
      "\n",
      " * Found with\n",
      "    Algorithm:     Newton's Method\n",
      "\n",
      " * Convergence measures\n",
      "    |x - x'|               = 1.31e-06 ≰ 0.0e+00\n",
      "    |x - x'|/|x'|          = 3.81e-07 ≰ 0.0e+00\n",
      "    |f(x) - f(x')|         = 1.17e-11 ≰ 0.0e+00\n",
      "    |f(x) - f(x')|/|f(x')| = 1.26e-13 ≰ 0.0e+00\n",
      "    |g(x)|                 = 1.33e-10 ≤ 1.0e-09\n",
      "\n",
      " * Work counters\n",
      "    Seconds run:   0  (vs limit Inf)\n",
      "    Iterations:    8\n",
      "    f(x) calls:    24\n",
      "    ∇f(x) calls:   24\n",
      "    ∇²f(x) calls:  8\n",
      "\n",
      "Optim.minimizer(res) = [1.5901214050582038, 0.28619365318378115, 0.23465202245353403, 1.155461775955513, -0.42143266899446646, 0.006618197844774856, 0.03409037197982027, -3.4243887069913703, -1.360588627579075]\n",
      "exp((Optim.minimizer(res))[end - 1]) = 0.032569184219741074\n",
      "exp((Optim.minimizer(res))[end]) = 0.2565097437972756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2565097437972756"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions, Optim, LinearAlgebra, ForwardDiff\n",
    "\n",
    "function NHN_mle(y, x, α, β, log_σ²_v, log_σ²_u)\n",
    "    σ²_v = exp(log_σ²_v)\n",
    "    σ²_u = exp(log_σ²_u)\n",
    "    σ_v  = exp(0.5*log_σ²_v)\n",
    "    σ_u  = exp(0.5*log_σ²_u)\n",
    "    σ²_star = (σ²_v*σ²_u)/(σ²_v + σ²_u)\n",
    "    ϵ  = y .- α .- x*β\n",
    "        \n",
    "    llike = 0.0          \n",
    "    for i in eachindex(ϵ)\n",
    "        llike += -log(0.5) - 0.5*log(σ²_v + σ²_u) +log(pdf(Normal(0, 1), ϵ[i]/sqrt(σ²_v + σ²_u))) + log(cdf(Normal(0,1), (-σ²_u*ϵ[i]/(σ²_v + σ²_u))/sqrt(σ²_star))) \n",
    "    end                                                    \n",
    "    return llike = -llike\n",
    "end\n",
    "\n",
    "\n",
    "nofxvar=6\n",
    "func = TwiceDifferentiable(vars -> NHN_mle(y, x, vars[1], vars[2:nofxvar+1], vars[end-1], vars[end]),\n",
    "                           ones(nofxvar+3); autodiff = :forward)\n",
    "\n",
    "x2=hcat(ones(size(y,1), 1), x); ols=inv(x2'x2)*(x2'y)\n",
    "myinit = vcat(ols, -0.1, -0.1) # or -0.1*ones(nofxvar+3)\n",
    "\n",
    "res= optimize(func, myinit, Newton(),\n",
    "                Optim.Options(g_tol = 1e-9,\n",
    "                              iterations = 100) )\n",
    "\n",
    "\n",
    "\n",
    "@show res\n",
    "@show Optim.minimizer(res)\n",
    "@show exp(Optim.minimizer(res)[end-1])\n",
    "@show exp(Optim.minimizer(res)[end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1efaea50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimation table is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9×3 Matrix{Float64}:\n",
       "  1.59012    0.349898     4.54453\n",
       "  0.286194   0.0698563    4.09689\n",
       "  0.234652   0.17648      1.32963\n",
       "  1.15546    0.0811715   14.2348\n",
       " -0.421433   0.0593928   -7.09569\n",
       "  0.0066182  0.0130428    0.507422\n",
       "  0.0340904  0.00803004   4.24536\n",
       "  0.0325692  0.00915964   3.55573\n",
       "  0.25651    0.0421414    6.08689"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coefficient vector\n",
    "_coevec = Optim.minimizer(res)\n",
    "res_coeff = deepcopy(_coevec)      # keep _coevec untouched\n",
    "res_coeff[end-1] = exp(_coevec[end-1])       # convert the unit \n",
    "res_coeff[end] = exp(_coevec[end])           # convert the unit \n",
    "\n",
    " \n",
    "# use Hessian matrix to obtain std. err.\n",
    "\n",
    "res_Hessian  = Optim.hessian!(func, _coevec)  # Hessain evaluated at the coeff vector, this is why we used deepcopy(), func is still in log unit, so we need to use _coevec (in log unit as well)\n",
    "var_cov_matrix = inv(res_Hessian)             # don't need the \"negative\" of Hessian. Why? Since already take negative in NHN_mle\n",
    "stderror  = sqrt.(diag(var_cov_matrix))\n",
    "stderror[end-1] = res_coeff[end-1]*stderror[end-1]  # convert the unit using the delta method, exp(hat rho)*sigma_rho\n",
    "stderror[end] = res_coeff[end]*stderror[end]\n",
    "t_stats = res_coeff ./ stderror\n",
    "res_table = hcat(res_coeff, stderror, t_stats)\n",
    "\n",
    "println(\"The estimation table is\")\n",
    "res_table |> display"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
